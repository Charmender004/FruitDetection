{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image Enhancing\n",
    "def preprocess_img(img):\n",
    "    # gray scale\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # enhance contrast\n",
    "    clahe = cv2.createCLAHE(clipLimit=3, tileGridSize=(16,16))\n",
    "    equalized_image = clahe.apply(gray)\n",
    "\n",
    "    # Gaussian blur\n",
    "    blurred_image = cv2.GaussianBlur(equalized_image, (5, 5), 0)\n",
    "\n",
    "    # Canny edge\n",
    "    edges = cv2.Canny(blurred_image, threshold1=60, threshold2=110)\n",
    "    return edges\n",
    "\n",
    "target_img = cv2.imread('./wortel.png')\n",
    "\n",
    "final_target = preprocess_img(target_img)\n",
    "\n",
    "# cv2.imshow('final',final_target)\n",
    "# cv2.waitKey(0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Detection\n",
    "\n",
    "sift = cv2.SIFT_create()\n",
    "orb = cv2.ORB_create()\n",
    "\n",
    "def detect_features(img):\n",
    "    # SIFT\n",
    "    kp_sift, des_sift = sift.detectAndCompute(img, None)\n",
    "    \n",
    "    # ORB\n",
    "    kp_orb, des_orb = orb.detectAndCompute(img, None)\n",
    "    \n",
    "    return kp_sift, des_sift, kp_orb, des_orb\n",
    "\n",
    "\n",
    "target_kp_sift, target_des_sift, target_kp_orb, target_des_orb = detect_features(final_target)\n",
    "\n",
    "target_desc = np.float32(target_des_sift)\n",
    "\n",
    "# all_keypoints = kp_sift + kp_orb\n",
    "    \n",
    "# img_with_keypoints = cv2.drawKeypoints(edges, all_keypoints, None, color=(0,255,0), flags=cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)\n",
    "\n",
    "# cv2.imshow('img', img_with_keypoints)\n",
    "# cv2.waitKey(0)\n",
    "# cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Feature Matching\n",
    "\n",
    "#FLANN\n",
    "flann = cv2.FlannBasedMatcher(dict(algorithm=1, trees=5),dict(checks=50))\n",
    "\n",
    "#BF\n",
    "bf = cv2.BFMatcher(cv2.NORM_L2, crossCheck=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def match_fruit(descriptors):\n",
    "    best_match = 0\n",
    "    best_match_data = None\n",
    "\n",
    "    for folder_path in os.listdir('Training/'):\n",
    "        for img_path in os.listdir('Training/'+folder_path):\n",
    "            img = cv2.imread('Training/'+folder_path+'/'+img_path)\n",
    "\n",
    "            if img is not None:\n",
    "                final_img = preprocess_img(img)\n",
    "\n",
    "                kp_sift, des_sift, kp_orb, des_orb = detect_features(final_img)\n",
    "                des_sift = np.float32(des_sift)\n",
    "                des_orb = np.float32(des_orb)\n",
    "\n",
    "                matches = flann.knnMatch(target_desc,des_sift,k=2)\n",
    "\n",
    "                # matches_mask = [[0,0] for _ in range(len(matches))]\n",
    "                \n",
    "                good_matches = []\n",
    "\n",
    "                curr_match = 0\n",
    "                for i, (fn,sm) in enumerate(matches):\n",
    "                    if fn.distance < 0.75 * sm.distance:\n",
    "                        # matches_mask[i] = [1,0]\n",
    "                        # curr_match+=1\n",
    "                        good_matches.append(fn)\n",
    "                \n",
    "                if (len(good_matches)>4):\n",
    "                    src = np.float32([target_kp_sift[m.queryIdx].pt for m in good_matches]).reshape(-1, 1, 2)\n",
    "                    dst = np.float32([kp_sift[m.trainIdx].pt for m in good_matches]).reshape(-1, 1, 2)\n",
    "                    \n",
    "                    M, mask = cv2.findHomography(src, dst, cv2.RANSAC, 5.0)\n",
    "\n",
    "                    matches_mask = mask.ravel().tolist()\n",
    "                    curr_match = sum(matches_mask)\n",
    "                    if best_match < curr_match:\n",
    "                        best_match = curr_match\n",
    "                        best_match_data={\n",
    "                            'img': img,\n",
    "                            'kp': kp_sift,\n",
    "                            'desc': des_sift,\n",
    "                            'matches': good_matches,\n",
    "                            'matches_mask':matches_mask\n",
    "                        }\n",
    "    \n",
    "    # result = cv2.drawMatchesKnn(\n",
    "    # target_img,\n",
    "    # target_kp_sift,\n",
    "    # best_match_data['img'],\n",
    "    # best_match_data['kp'],\n",
    "    # best_match_data['matches'],\n",
    "    # None,\n",
    "    # matchColor=[255,0,0],\n",
    "    # matchesMask=best_match_data['matches_mask'],\n",
    "    # singlePointColor=[0,0,255]\n",
    "    # )\n",
    "\n",
    "    result = cv2.drawMatches(\n",
    "        target_img,\n",
    "        target_kp_sift,\n",
    "        best_match_data['img'],\n",
    "        best_match_data['kp'],\n",
    "        best_match_data['matches'],\n",
    "        None,\n",
    "        # matchColor=[255, 0, 0],\n",
    "        matchesMask=best_match_data['matches_mask'],\n",
    "        # singlePointColor=[0, 0, 255]\n",
    "    )\n",
    "\n",
    "    cv2.imshow('result',result)\n",
    "    cv2.waitKey(0)\n",
    "\n",
    "    return \"Fruit Detected\" if descriptors is not None else \"No Fruit Detected\"\n",
    "\n",
    "# match_fruit(target_desc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def making_model():\n",
    "    desc = {}\n",
    "    for fruit in os.listdir('Training/'):\n",
    "        folder_path = os.path.join('Training', fruit)\n",
    "        \n",
    "        if os.path.isdir(folder_path):\n",
    "            class_desc = []\n",
    "            \n",
    "            for img_path in os.listdir(folder_path):\n",
    "                img = cv2.imread(os.path.join(folder_path, img_path))\n",
    "                \n",
    "                if img is not None:\n",
    "                    final_img = preprocess_img(img)\n",
    "                    kp_sift, des_sift, kp_orb, des_orb = detect_features(final_img)\n",
    "                    \n",
    "                    if des_sift is not None:\n",
    "                        class_desc.append(np.float32(des_sift))\n",
    "            \n",
    "            if class_desc:\n",
    "                desc[fruit] = np.vstack(class_desc)\n",
    "    \n",
    "    with open('fruit_detection_model.pkl', 'wb') as file:\n",
    "        pickle.dump(desc, file)\n",
    "\n",
    "# making_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "descriptor_path = 'fruit_detection_model.pkl'\n",
    "\n",
    "# with open(descriptor_path, 'rb') as file:\n",
    "#     fruit_descriptors = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def match_fruit_model(descriptors):\n",
    "    best_match = 0\n",
    "    best_fruit = \"Unknown\"\n",
    "    \n",
    "    # Compare with each fruit's precomputed descriptors\n",
    "    for fruit_class, stored_descriptors in fruit_descriptors.items():\n",
    "        if descriptors is not None:\n",
    "            matches = flann.knnMatch(descriptors, stored_descriptors, k=2)\n",
    "            \n",
    "            good_matches = [m for m, n in matches if m.distance < 0.75 * n.distance]\n",
    "            \n",
    "            if len(good_matches) > best_match:\n",
    "                best_match = len(good_matches)\n",
    "                best_fruit = fruit_class\n",
    "    \n",
    "    return best_fruit if best_match > 0 else \"No Fruit Detected\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'fruit_descriptors' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_20844\\3142221756.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     29\u001b[0m     \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdestroyAllWindows\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 31\u001b[1;33m \u001b[0mimg_detection_live\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_20844\\3142221756.py\u001b[0m in \u001b[0;36mimg_detection_live\u001b[1;34m()\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m         \u001b[1;31m# Image matching\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m         \u001b[0mfruit_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmatch_fruit_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdes_sift\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m         \u001b[1;31m# Display frame\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_20844\\2353161316.py\u001b[0m in \u001b[0;36mmatch_fruit_model\u001b[1;34m(descriptors)\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[1;31m# Compare with each fruit's precomputed descriptors\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m     \u001b[1;32mfor\u001b[0m \u001b[0mfruit_class\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstored_descriptors\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mfruit_descriptors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mdescriptors\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m             \u001b[0mmatches\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mflann\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mknnMatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdescriptors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstored_descriptors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'fruit_descriptors' is not defined"
     ]
    }
   ],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "def img_detection_live():\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        # Preprocess image\n",
    "        processed_frame = preprocess_img(frame)\n",
    "\n",
    "        # Feature extraction memakai sift dan orb\n",
    "        kp_sift, des_sift, kp_orb, des_orb = detect_features(processed_frame)\n",
    "\n",
    "        frame_kp = cv2.drawKeypoints(frame, kp_sift, None, color=(0,255,0),\n",
    "                                                flags=cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)\n",
    "\n",
    "        # Image matching\n",
    "        fruit_result = match_fruit_model(des_sift)\n",
    "\n",
    "        # Display frame\n",
    "        cv2.putText(frame_kp, fruit_result, (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 0, 0), 2)\n",
    "        cv2.imshow(\"Fruit Detection\", frame_kp)\n",
    "\n",
    "        # Kalau mw keluar pencet q\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "# img_detection_live()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
