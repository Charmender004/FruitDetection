{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read image\n",
    "\n",
    "# train_path = 'fruits-360_dataset_100x100/fruits-360/Training'\n",
    "# fruits = os.listdir(train_path)\n",
    "\n",
    "# for idx, fruit in enumerate(fruits):\n",
    "#     full_path = train_path + '/' + fruit\n",
    "\n",
    "#     for img_name in os.listdir(full_path):\n",
    "#         img_full_path = full_path + '/' + img_name\n",
    "#         img = cv2.imread(img_full_path)\n",
    "#         cv2.imshow(img_name,img)\n",
    "#         cv2.waitKey(0)\n",
    "#         cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image Enhancing\n",
    "def preprocess_img(img):\n",
    "    # gray scale\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # enhance contrast\n",
    "    clahe = cv2.createCLAHE(clipLimit=3.0, tileGridSize=(16,16))\n",
    "    equalized_image = clahe.apply(gray)\n",
    "\n",
    "    # Gaussian blur\n",
    "    blurred_image = cv2.GaussianBlur(equalized_image, (5, 5), 0)\n",
    "\n",
    "    # Canny edge\n",
    "    edges = cv2.Canny(blurred_image, threshold1=50, threshold2=100)\n",
    "    return edges\n",
    "\n",
    "target_img = cv2.imread('./r0_0.jpg')\n",
    "\n",
    "final_target = preprocess_img(target_img)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Detection\n",
    "\n",
    "sift = cv2.SIFT_create()\n",
    "orb = cv2.ORB_create()\n",
    "\n",
    "def detect_features(img):\n",
    "    # SIFT\n",
    "    kp_sift, des_sift = sift.detectAndCompute(img, None)\n",
    "    \n",
    "    # ORB\n",
    "    kp_orb, des_orb = orb.detectAndCompute(img, None)\n",
    "    \n",
    "    return kp_sift, des_sift, kp_orb, des_orb\n",
    "\n",
    "\n",
    "target_kp_sift, target_des_sift, target_kp_orb, target_des_orb = detect_features(target_img)\n",
    "\n",
    "# target_desc = np.float32(target_des_sift)\n",
    "target_desc = np.float32(target_des_orb)\n",
    "\n",
    "# all_keypoints = kp_sift + kp_orb\n",
    "    \n",
    "# img_with_keypoints = cv2.drawKeypoints(edges, all_keypoints, None, color=(0,255,0), flags=cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)\n",
    "\n",
    "# cv2.imshow('img', img_with_keypoints)\n",
    "# cv2.waitKey(0)\n",
    "# cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Feature Matching\n",
    "\n",
    "#FLANN\n",
    "flann = cv2.FlannBasedMatcher(dict(algorithm=1, trees=5),dict(checks=50))\n",
    "# match = flann.knnMatch(target_desc,img_desc,2)\n",
    "\n",
    "#BF\n",
    "bf = cv2.BFMatcher(cv2.NORM_L2, crossCheck=False)\n",
    "# match = bf.match(target_desc, img_desc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Fruit Detected'"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def match_fruit(descriptors):\n",
    "    best_match = 0\n",
    "    best_match_data = None\n",
    "\n",
    "    for folder_path in os.listdir('Training/'):\n",
    "        for img_path in os.listdir('Training/'+folder_path):\n",
    "            img = cv2.imread('Training/'+folder_path+'/'+img_path)\n",
    "\n",
    "            if img is not None:\n",
    "                final_img = preprocess_img(img)\n",
    "\n",
    "                kp_sift, des_sift, kp_orb, des_orb = detect_features(final_img)\n",
    "                des_sift = np.float32(des_sift)\n",
    "                des_orb = np.float32(des_orb)\n",
    "\n",
    "                matches = flann.knnMatch(target_desc,des_orb,k=2)\n",
    "\n",
    "                matches_mask = [[0,0] for _ in range(len(matches))]\n",
    "                curr_match = 0\n",
    "                for i, (fn,sm) in enumerate(matches):\n",
    "                    if fn.distance < 0.7 * sm.distance:\n",
    "                        matches_mask[i] = [1,0]\n",
    "                        curr_match+=1\n",
    "                \n",
    "                # Tambahin RANSAC (belum)\n",
    "\n",
    "                if best_match < curr_match:\n",
    "                    best_match = curr_match\n",
    "                    best_match_data={\n",
    "                        'img': img,\n",
    "                        'kp': kp_sift,\n",
    "                        'desc': des_sift,\n",
    "                        'matches': matches,\n",
    "                        'matches_mask':matches_mask\n",
    "                    }\n",
    "    \n",
    "    result = cv2.drawMatchesKnn(\n",
    "    target_img,\n",
    "    target_kp_sift,\n",
    "    best_match_data['img'],\n",
    "    best_match_data['kp'],\n",
    "    best_match_data['matches'],\n",
    "    None,\n",
    "    matchColor=[255,0,0],\n",
    "    matchesMask=best_match_data['matches_mask'],\n",
    "    singlePointColor=[0,0,255]\n",
    "    )\n",
    "\n",
    "    cv2.imshow('result',result)\n",
    "    cv2.waitKey(0)\n",
    "\n",
    "    return \"Fruit Detected\" if descriptors is not None else \"No Fruit Detected\"\n",
    "\n",
    "# match_fruit(target_desc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "descriptor_path = 'fruit_detection_model.pkl'\n",
    "\n",
    "# with open(descriptor_path, 'rb') as file:\n",
    "#     fruit_descriptors = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "def match_fruit_model(descriptors):\n",
    "    best_match = 0\n",
    "    best_fruit = \"Unknown\"\n",
    "    \n",
    "    # Compare with each fruit's precomputed descriptors\n",
    "    for fruit_class, stored_descriptors in fruit_descriptors.items():\n",
    "        if descriptors is not None:\n",
    "            matches = flann.knnMatch(descriptors, stored_descriptors, k=2)\n",
    "            \n",
    "            good_matches = [m for m, n in matches if m.distance < 0.75 * n.distance]\n",
    "            \n",
    "            if len(good_matches) > best_match:\n",
    "                best_match = len(good_matches)\n",
    "                best_fruit = fruit_class\n",
    "    \n",
    "    return best_fruit if best_match > 0 else \"No Fruit Detected\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "def making_model():\n",
    "    desc = {}\n",
    "    for fruit in os.listdir('Training/'):\n",
    "        folder_path = os.path.join('Training', fruit)\n",
    "        \n",
    "        if os.path.isdir(folder_path):\n",
    "            class_desc = []\n",
    "            \n",
    "            for img_path in os.listdir(folder_path):\n",
    "                img = cv2.imread(os.path.join(folder_path, img_path))\n",
    "                \n",
    "                if img is not None:\n",
    "                    final_img = preprocess_img(img)\n",
    "                    kp_sift, des_sift, kp_orb, des_orb = detect_features(final_img)\n",
    "                    \n",
    "                    if des_sift is not None:\n",
    "                        class_desc.append(np.float32(des_sift))\n",
    "            \n",
    "            if class_desc:\n",
    "                desc[fruit] = np.vstack(class_desc)\n",
    "    \n",
    "    with open(descriptor_path, 'wb') as file:\n",
    "        pickle.dump(desc, file)\n",
    "\n",
    "# making_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "def img_detection_live():\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        # Preprocess image\n",
    "        processed_frame = preprocess_img(frame)\n",
    "\n",
    "        # Feature extraction memakai sift dan orb\n",
    "        kp_sift, des_sift, kp_orb, des_orb = detect_features(processed_frame)\n",
    "\n",
    "        frame_kp = cv2.drawKeypoints(frame, kp_sift, None, color=(0,255,0),\n",
    "                                                flags=cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)\n",
    "\n",
    "        # Image matching\n",
    "        fruit_result = match_fruit_model(des_sift)\n",
    "\n",
    "        # Display frame\n",
    "        cv2.putText(frame_kp, fruit_result, (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 0, 0), 2)\n",
    "        cv2.imshow(\"Fruit Detection\", frame_kp)\n",
    "\n",
    "        # Kalau mw keluar pencet q\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "# img_detection_live()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
