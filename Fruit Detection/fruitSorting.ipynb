{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image Enhancing\n",
    "\n",
    "def preprocess_img(img):\n",
    "    resized_img = cv2.resize(img, (256,256))\n",
    "\n",
    "    gray = cv2.cvtColor(resized_img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    clahe = cv2.createCLAHE(3, (8,8))\n",
    "    equalized_img = clahe.apply(gray)\n",
    "\n",
    "    blurred_img = cv2.medianBlur(equalized_img, 5)\n",
    "\n",
    "    # edges = cv2.Canny(blurred_img, 60, 90)\n",
    "    # cv2.imshow('img', blurred_img)\n",
    "    # cv2.waitKey(0)\n",
    "    # cv2.destroyAllWindows()\n",
    "    hsv_img = cv2.cvtColor(resized_img, cv2.COLOR_BGR2HSV)\n",
    "    hsv_img = cv2.medianBlur(hsv_img, 5)\n",
    "    hist_h = cv2.calcHist([hsv_img], [0], None, [180], [0, 180]) \n",
    "    hist_s = cv2.calcHist([hsv_img], [1], None, [256], [0, 256])\n",
    "    hist_v = cv2.calcHist([hsv_img], [2], None, [256], [0, 256])\n",
    "\n",
    "    hist_h = hist_h / np.linalg.norm(hist_h)\n",
    "    hist_s = hist_s / np.linalg.norm(hist_s)\n",
    "    hist_v = hist_v / np.linalg.norm(hist_v)\n",
    "\n",
    "    color_hist = np.concatenate([hist_h, hist_s, hist_v]).flatten()\n",
    "\n",
    "    return blurred_img, color_hist\n",
    "\n",
    "target_img = cv2.imread('./rotten-apple-13258722.webp')\n",
    "\n",
    "final_target, target_hist = preprocess_img(target_img)\n",
    "\n",
    "# cv2.imshow('final',final_target)\n",
    "# cv2.waitKey(0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Detection\n",
    "\n",
    "sift = cv2.SIFT_create()\n",
    "\n",
    "def extract_features(img):\n",
    "    kp_sift, des_sift = sift.detectAndCompute(img, None)\n",
    "    \n",
    "    return kp_sift, des_sift\n",
    "\n",
    "target_kp_sift, target_des_sift = extract_features(final_target)\n",
    "\n",
    "target_desc = np.float32(target_des_sift)\n",
    "\n",
    "# all_keypoints = kp_sift + kp_orb\n",
    "    \n",
    "# img_with_keypoints = cv2.drawKeypoints(target_img, target_kp_orb, None, color=(0,255,0), flags=cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)\n",
    "\n",
    "# cv2.imshow('img', img_with_keypoints)\n",
    "# cv2.waitKey(0)\n",
    "# cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Feature Matching\n",
    "\n",
    "flann = cv2.FlannBasedMatcher(dict(algorithm=1, trees=5),dict(checks=50))\n",
    "\n",
    "bf = cv2.BFMatcher(cv2.NORM_L2, crossCheck=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def match_fruit(descriptors):\n",
    "    best_match = 0\n",
    "    best_match_data = None\n",
    "\n",
    "    for folder_path in os.listdir('Train/'):\n",
    "        for img_path in os.listdir('Train/'+folder_path):\n",
    "            img = cv2.imread('Train/'+folder_path+'/'+img_path)\n",
    "\n",
    "            if img is not None:\n",
    "                final_img, img_hist = preprocess_img(img)\n",
    "                # if folder_path=='freshbanana':\n",
    "                #     cv2.imshow('img', final_img)\n",
    "                #     cv2.waitKey(0)\n",
    "                #     cv2.destroyAllWindows()\n",
    "                kp_sift, des_sift= extract_features(final_img)\n",
    "                des_sift = np.float32(des_sift)\n",
    "                # if folder_path == 'freshbanana':\n",
    "                #     img_with_keypoints = cv2.drawKeypoints(final_img, kp_sift, None, color=(0,255,0), flags=cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)\n",
    "\n",
    "                #     cv2.imshow('img', img_with_keypoints)\n",
    "                #     cv2.waitKey(0)\n",
    "                #     cv2.destroyAllWindows()\n",
    "\n",
    "                matches = flann.knnMatch(descriptors,des_sift,k=2)\n",
    "\n",
    "                good_matches = []\n",
    "\n",
    "                curr_match = 0\n",
    "                for i, (fn,sm) in enumerate(matches):\n",
    "                    if fn.distance < 0.75 * sm.distance:\n",
    "                        good_matches.append(fn)\n",
    "\n",
    "                hist_score = cv2.compareHist(target_hist, img_hist, cv2.HISTCMP_CORREL)\n",
    "                \n",
    "                if (len(good_matches)>4):\n",
    "                    src = np.float32([target_kp_sift[m.queryIdx].pt for m in good_matches]).reshape(-1, 1, 2)\n",
    "                    dst = np.float32([kp_sift[m.trainIdx].pt for m in good_matches]).reshape(-1, 1, 2)\n",
    "                    \n",
    "                    _, mask = cv2.findHomography(src, dst, cv2.RANSAC, 5.0)\n",
    "\n",
    "                    matches_mask = mask.ravel().tolist()\n",
    "                    curr_match = sum(matches_mask)\n",
    "\n",
    "                    final_match = (hist_score * 0.5) + (curr_match * 0.5)\n",
    "                    if best_match < final_match:\n",
    "                        best_match = final_match\n",
    "                        best_match_data={\n",
    "                            'img': img,\n",
    "                            'kp': kp_sift,\n",
    "                            'desc': des_sift,\n",
    "                            'matches': good_matches,\n",
    "                            'matches_mask':matches_mask\n",
    "                        }\n",
    "    \n",
    "    result = cv2.drawMatches(\n",
    "        cv2.resize(target_img,(256,256)),\n",
    "        target_kp_sift,\n",
    "        cv2.resize(best_match_data['img'],(256,256)),\n",
    "        best_match_data['kp'],\n",
    "        best_match_data['matches'],\n",
    "        None,\n",
    "        matchesMask=best_match_data['matches_mask'],\n",
    "    )\n",
    "\n",
    "    cv2.imshow('result',result)\n",
    "    cv2.waitKey(0)\n",
    "\n",
    "match_fruit(target_desc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def making_model():\n",
    "#     desc = {}\n",
    "#     for fruit in os.listdir('Training/'):\n",
    "#         folder_path = os.path.join('Training', fruit)\n",
    "        \n",
    "#         if os.path.isdir(folder_path):\n",
    "#             class_desc = []\n",
    "            \n",
    "#             for img_path in os.listdir(folder_path):\n",
    "#                 img = cv2.imread(os.path.join(folder_path, img_path))\n",
    "                \n",
    "#                 if img is not None:\n",
    "#                     final_img = preprocess_img(img)\n",
    "#                     kp_sift, des_sift, kp_orb, des_orb = extract_features(final_img)\n",
    "                    \n",
    "#                     if des_sift is not None:\n",
    "#                         class_desc.append(np.float32(des_sift))\n",
    "            \n",
    "#             if class_desc:\n",
    "#                 desc[fruit] = np.vstack(class_desc)\n",
    "    \n",
    "#     with open('fruit_detection_model.pkl', 'wb') as file:\n",
    "#         pickle.dump(desc, file)\n",
    "\n",
    "# # making_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# descriptor_path = 'fruit_detection_model.pkl'\n",
    "\n",
    "# with open(descriptor_path, 'rb') as file:\n",
    "#     fruit_descriptors = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def match_fruit_model(descriptors):\n",
    "#     best_match = 0\n",
    "#     best_fruit = \"Unknown\"\n",
    "    \n",
    "#     for fruit_class, stored_descriptors in fruit_descriptors.items():\n",
    "#         if descriptors is not None:\n",
    "#             matches = flann.knnMatch(descriptors, stored_descriptors, k=2)\n",
    "            \n",
    "#             good_matches = [m for m, n in matches if m.distance < 0.75 * n.distance]\n",
    "            \n",
    "#             if len(good_matches) > best_match:\n",
    "#                 best_match = len(good_matches)\n",
    "#                 best_fruit = fruit_class\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cap = cv2.VideoCapture(0)\n",
    "# def img_detection_live():\n",
    "#     while True:\n",
    "#         ret, frame = cap.read()\n",
    "#         if not ret:\n",
    "#             break\n",
    "\n",
    "#         processed_frame = preprocess_img(frame)\n",
    "\n",
    "#         kp_sift, des_sift, kp_orb, des_orb = extract_features(processed_frame)\n",
    "\n",
    "#         frame_kp = cv2.drawKeypoints(frame, kp_sift, None, color=(0,255,0),\n",
    "#                                                 flags=cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)\n",
    "\n",
    "#         fruit_result = match_fruit_model(des_sift)\n",
    "\n",
    "#         cv2.putText(frame_kp, fruit_result, (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 0, 0), 2)\n",
    "#         cv2.imshow(\"Fruit Detection\", frame_kp)\n",
    "\n",
    "#         # Kalau mw keluar pencet q\n",
    "#         if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "#             break\n",
    "\n",
    "#     cap.release()\n",
    "#     cv2.destroyAllWindows()\n",
    "\n",
    "# # img_detection_live()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
